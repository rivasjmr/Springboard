{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose is to optimize the RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  (60000, 784)  Labels:  (60000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "#   Training data\n",
    "df_training = pd.read_csv('C:\\\\Users\\\\rivas\\\\OneDrive\\\\Documents\\\\JMR\\\\Education\\\\Springboard\\\\Projects\\\\Capstone1\\\\fashionmnisttrain.csv')\n",
    "\n",
    "#   split data table into data Features (x) and class labels (y)\n",
    "xdf_train = df_training.iloc[:, 1:]\n",
    "ydf_train = df_training.iloc[:, :1]\n",
    "print('Features: ',xdf_train.shape, ' Labels: ',ydf_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  (10000, 784)  Labels:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#   Test data\n",
    "#   split data table into data Features (x) and class labels (y)\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\rivas\\\\OneDrive\\\\Documents\\\\JMR\\\\Education\\\\Springboard\\\\Projects\\\\Capstone1\\\\fashionmnisttest.csv')\n",
    "\n",
    "#   split data table into data Features (x) and class labels (y)\n",
    "xdf_test = df_test.iloc[:, 1:]\n",
    "ydf_test = df_test.iloc[:, :1]\n",
    "print('Features: ',xdf_test.shape, ' Labels: ',ydf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#   Convert to numpy array\n",
    "X_train = xdf_train.as_matrix()\n",
    "y_train = ydf_train.as_matrix()\n",
    "X_test = xdf_test.as_matrix()\n",
    "y_test = ydf_test.as_matrix()\n",
    "\n",
    "# Reshape array\n",
    "y2_train = np.ravel( y_train[ : , 0] ) \n",
    "y2_test = np.ravel( y_test[ : , 0] ) \n",
    "\n",
    "#\n",
    "print(X_train.shape, y2_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce the dimensionality of a data set. To be able to process large datasets used\n",
    "principal component analysis (PCA) to reduce the dimensionality of a data set.\n",
    "This is an Unsupervised clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rivas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Standardizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(X_train)\n",
    "\n",
    "# PCA in scikit-learn  \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA().fit(X_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wil use 50 components  for the PCA to reduce the dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 50)\n"
     ]
    }
   ],
   "source": [
    "# PCA - Using 50 components for training data\n",
    "sklearn50_pca = PCA(n_components=50)\n",
    "X_50 = sklearn50_pca.fit_transform(X_std)\n",
    "print(X_50.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rivas\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 50)\n"
     ]
    }
   ],
   "source": [
    "# Test data - Using 50 components\n",
    "X_std = StandardScaler().fit_transform(X_test)\n",
    "pca = PCA().fit(X_std)\n",
    "sklearn50_pca = PCA(n_components=50)\n",
    "Xtest_50 = sklearn50_pca.fit_transform(X_std)\n",
    "print(Xtest_50.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the initial Randon Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "# 1 - Import the model\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 - Make an instance of the Model\n",
    "RF_clf = RandomForestClassifier(n_jobs=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 - Training the model: Using PCA 50 (X_50) for training data\n",
    "#     fitting the model\n",
    "RF_clf.fit(X_50, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4 - Predict the response\n",
    "RF_clf_predict = RF_clf.predict(Xtest_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6948\n"
     ]
    }
   ],
   "source": [
    "# 5 - Evaluate accuracy\n",
    "#     loading libraries\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print ('Accuracy:', accuracy_score(y2_test, RF_clf_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start the process to optimize the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# To use RandomizedSearchCV, we first need\n",
    "# to create a parameter grid to sample from during fitting:\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First create the base model to tune\n",
    "RF_clf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random search of parameters, using 2 fold cross validation, \n",
    "# search across 10 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = RF_clf, param_distributions = random_grid, n_iter = 10, cv = 2, verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 72.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the random search model\n",
    "rf_random.fit(X_50, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 50, 'max_features': 'auto', 'n_estimators': 1400}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if random search yielded a better model, we compare the\n",
    "base model with the best random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=2,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish Base Model\n",
    "base_model = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "base_model.fit(X_50, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict the response\n",
    "base_model_predict = base_model.predict(Xtest_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6948\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', accuracy_score(y2_test, base_model_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=50, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1400, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish new model with best parameters\n",
    "# {'max_depth': 50, 'max_features': 'auto', 'n_estimators': 1400}\n",
    "new_model = RandomForestClassifier(max_depth=50, max_features='auto', n_estimators=1400,n_jobs=-1, random_state=42 )\n",
    "new_model.fit(X_50, y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model_predict = new_model.predict(Xtest_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare Accurracy of both models[{000214A0-0000-0000-C000-000000000046}]\n",
    "Prop3=19,2\n",
    "[InternetShortcut]\n",
    "IDList=\n",
    "URL=http://localhost:8888/notebooks/SP%20Capstone%201/Fine%20tuning%20RF.ipynb#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy: 0.6948\n",
      "New Model Accuracy : 0.7734\n"
     ]
    }
   ],
   "source": [
    "print ('Base Model Accuracy:', accuracy_score(y2_test, base_model_predict))\n",
    "print ('New Model Accuracy :', accuracy_score(y2_test, new_model_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
